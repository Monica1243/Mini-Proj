import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score


file = pd.read_csv('labelled_dysx.csv')
print('Read file')

file.head()

file.shape

file.describe()

file.isna()

file.dropna()

# label 0 - low
# label 1 - Moderate
# label 2 - High
features = ['Language_vocab','Memory','Speed','Visual_discrimination','Audio_Discrimination','Survey_Score']
X = file[features]
y = file['Label']

x_train, x_test,y_train, y_test = train_test_split(X,y, random_state = 1)

x_train.shape

# Accuracy =(TP+TN)/(TP+TN+FP+FN)
# Precision = TP/(TP+FP)
# Recall = TP/(TP+FN)
# F1 Score=2*((precision * recall)/(precision +recall)
  
              
              #Random Forest Classifier
rf = RandomForestClassifier()
rf.fit(x_train,y_train)

rf_pred = rf.predict(x_test)

rf_loss = mean_absolute_error(y_test,rf_pred)
print(rf_loss)

print(accuracy_score(y_test, rf_pred))

print(classification_report(y_test, rf_pred))

          
                #KNeighbors Classifier

knn = KNeighborsClassifier()
knn.fit(x_train,y_train)

knn_pred = knn.predict(x_test)

knn_loss = mean_absolute_error(y_test,knn_pred)

print(knn_loss)
print(accuracy_score(y_test, knn_pred))

print(classification_report(y_test, knn_pred))


        #Decision Tree Regressor
dt = DecisionTreeRegressor()
dt.fit(x_train,y_train)

dt_pred = knn.predict(x_test)

dt_loss = mean_absolute_error(y_test,dt_pred)

print(dt_loss)
print(accuracy_score(y_test, dt_pred))

print(classification_report(y_test, dt_pred))


        #Decision Tree Classifier
dtc = DecisionTreeClassifier()
dtc.fit(x_train,y_train)

dtc_pred = knn.predict(x_test)

dtc_loss = mean_absolute_error(y_test,dtc_pred)

print(dtc_loss)
print(accuracy_score(y_test, dtc_pred))

print(classification_report(y_test, dtc_pred))


         # AdaBoost Classifier
abc = AdaBoostClassifier(random_state = 1)
abc.fit(x_train,y_train)

abc_pred = knn.predict(x_test)

abc_loss = mean_absolute_error(y_test,abc_pred)

print(abc_loss)
print(accuracy_score(y_test, abc_pred))

print(classification_report(y_test, abc_pred))

print("Algorithm","                   ","Mean Absolute Error  ")
print()
print("Random Forest          ", "       ",rf_loss)
print("KNeighbors             ", "       ",knn_loss)
print("Decison Tree Regressor ", "       ",dt_loss)
print("Decison Tree Classifier", "       ",dtc_loss)
print("Ada Boost Classifier   ", "       ",abc_loss)
